{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfcf38e5",
   "metadata": {},
   "source": [
    "아래 코드를 참고해, 수정 사용하였습니다.\n",
    "\n",
    "https://github.com/gmattl/Thesis_OpenMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "098c596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2abcab7",
   "metadata": {},
   "source": [
    "# 전처리가 완료된 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "94c49624",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train_done.csv', index_col=0)\n",
    "test = pd.read_csv('./test_done.csv', index_col=0)\n",
    "validation = pd.read_csv('./validation_done.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "630b114a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_text = list(train['full_log'])\n",
    "train_level = np.array(train['level'])\n",
    "\n",
    "test_text = list(test['full_log'])\n",
    "\n",
    "valid_text = list(validation['full_log'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43c6b317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9171\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 250\n",
    "EMBEDDING_DIM = 200\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_text)\n",
    "print(len(tokenizer.word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96bfaf27",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(472550, 250)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X = tokenizer.texts_to_sequences(train_text)\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45c9a6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = to_categorical(train_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db77fb7",
   "metadata": {},
   "source": [
    "# 학습된 모델 불러오기\n",
    "- simpleRNN\n",
    "- activation = 'linear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43937ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "F1_MACRO = tfa.metrics.F1Score(num_classes=7, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88420747",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "\n",
    "def my_categorical_crossentropy(y_true, y_pred):\n",
    "    return K.categorical_crossentropy(y_true, y_pred, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b97e949",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import keras.losses\n",
    "\n",
    "model = load_model('model_RNN_02.h5', compile=False)\n",
    "model.compile(optimizer=opt, loss=my_categorical_crossentropy, metrics=[F1_MACRO])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35df835",
   "metadata": {},
   "source": [
    "# 필요한 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "679af615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(vector):\n",
    "    e = np.exp(vector)\n",
    "    return e / e.sum()\n",
    "\n",
    "# foo = [1, 3, 2]\n",
    "# foo_result = softmax(foo)\n",
    "# foo_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "86db35a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_predict(X):\n",
    "    result = model.predict(X)\n",
    "    \n",
    "    # Activation vector\n",
    "    act = result.copy()\n",
    "    \n",
    "    # predicted label\n",
    "    for n in range(X.shape[0]):\n",
    "        result[n] = softmax(result[n])\n",
    "    pred = [np.argmax(i) for i in result]\n",
    "    \n",
    "    return act, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f3aab84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_setting(act, pred, true_labels):\n",
    "    '''\n",
    "    올바르게 분류된 train 데이터만 활용합니다.\n",
    "    act, pred: my_predict 함수의 리턴값\n",
    "    true_labels : to_categorical(Y)\n",
    "    '''\n",
    "    true_labels = [np.argmax(i) for i in Y]\n",
    "\n",
    "    idx = 0\n",
    "    mismatch = []\n",
    "\n",
    "    for i in pred:\n",
    "        if i != true_labels[idx]:\n",
    "            mismatch.append(idx)\n",
    "        idx = idx + 1\n",
    "        \n",
    "    # 클래스가 잘못 분류된 인덱스를 삭제\n",
    "    for wrong_idx in mismatch:\n",
    "        del pred[wrong_idx]\n",
    "        del true_labels[wrong_idx]\n",
    "        \n",
    "    act = np.delete(act, mismatch, axis=0)\n",
    "    \n",
    "    return act, pred, true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "204ca99f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import libmr\n",
    "import scipy.spatial.distance as spd\n",
    "\n",
    "# cython 설치 후 limbr 설치\n",
    "\n",
    "\n",
    "def compute_mav_distances(activations, predictions, true_labels):\n",
    "    \"\"\"\n",
    "    각 클래스별 MAV(mean_activations)와 MAV까지의 유클리디안-코사인 거리(eucos_dist)를 구합니다.\n",
    "    :activations: 각 데이터의 logit\n",
    "    :predictions: 각 데이터의 예측 클래스\n",
    "    :true_labels: 각 데이터의 실제 클래스\n",
    "    \"\"\"\n",
    "    \n",
    "    mean_activations = list()\n",
    "    eucos_dist = np.zeros(activations.shape[0])\n",
    "\n",
    "    for cl in range(7): # 클래스 개수\n",
    "        print('위험도 등급', cl)\n",
    "\n",
    "        # 현재 클래스에 해당하는 인덱스\n",
    "        cl_index = [] \n",
    "        for i in range(0, len(predictions)): \n",
    "            if predictions[i] == cl: \n",
    "                cl_index.append(i)\n",
    "\n",
    "        # 현재 클래스의 인덱스에 해당하는 AV    \n",
    "        cl_activations = []\n",
    "        for idx in cl_index:\n",
    "            act = activations[idx]\n",
    "            cl_activations.append(act)\n",
    "        print('올바르게 분류된 데이터 개수', len(cl_index))\n",
    "\n",
    "        # 현재 클래스의 AV 평균(MAV)\n",
    "        mean_act = []\n",
    "        for c in range(7):\n",
    "            act_sum = 0\n",
    "            for i in range(len(cl_activations)):\n",
    "                act_sum += cl_activations[i][c]\n",
    "            m = act_sum/len(cl_activations)\n",
    "            mean_act.append(m)\n",
    "        mean_activations.append(mean_act)\n",
    "\n",
    "        # MAV까지의 거리\n",
    "        for col in cl_index:\n",
    "            eucos_dist[col] = spd.euclidean(mean_act, activations[col])/200. + spd.cosine(mean_act, activations[col])\n",
    "    \n",
    "    return mean_activations, eucos_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bd9a58fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weibull_tailfitting(eucos_dist, mean_activations, taillength=20):\n",
    "    \"\"\"\n",
    "    각 클래스별 weibull 모델을 생성합니다.\n",
    "    :eucos_dist: MAV와 데이터 간 거리\n",
    "    :mean_activations: 클래스별 MAV\n",
    "    :taillength: weibull 모델 생성시 활용할 상위 거리값 개수\n",
    "    \"\"\"\n",
    "\n",
    "    weibull_model = {}\n",
    "    \n",
    "    for cl in range(7):\n",
    "\n",
    "        # 현재 클래스에 해당하는 인덱스\n",
    "        label_indexes = [] \n",
    "        for i in range(0, len(predictions)): \n",
    "            if predictions[i] == cl: \n",
    "                label_indexes.append(i)\n",
    "\n",
    "        eucos_dist_list = []\n",
    "        for idx in label_indexes:\n",
    "            eucos = eucos_dist[idx]\n",
    "            eucos_dist_list.append(eucos)\n",
    "        \n",
    "        # weibull_model : 클래스별 eucos_distances, mean_vec, weibull_model\n",
    "        weibull_model[cl] = {}\n",
    "        weibull_model[cl]['eucos_distances'] = eucos_dist_list\n",
    "        weibull_model[cl]['mean_vec'] = mean_activations[cl]\n",
    "        weibull_model[cl]['weibull_model'] = []\n",
    "\n",
    "        mr = libmr.MR(verbose=True)\n",
    "        tailtofit = sorted(weibull_model[cl]['eucos_distances'])[-taillength:]\n",
    "        mr.fit_high(tailtofit, len(tailtofit))\n",
    "        weibull_model[cl]['weibull_model'] = mr\n",
    "    \n",
    "    return weibull_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2a8fbb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_open_max_probability(openmax_known_score, openmax_unknown_score):\n",
    "    \"\"\"\n",
    "    OpenMax 확률을 구합니다\n",
    "    :openmax_known_score: 기존 클래스에 대한 weibull 값\n",
    "    :openmax_unknown_score: unknown 클래스에 대한 weibull 값\n",
    "    :return: 정규화(softmax)가 완료된 최종 OpenMax 확률\n",
    "    \"\"\"\n",
    "\n",
    "    prob_closed, prob_open, scores = [], [], []\n",
    "\n",
    "    # 소프트맥스\n",
    "    for category in range(7):\n",
    "        scores += [np.exp(openmax_known_score[category])]\n",
    "    total_denominator = np.sum(np.exp(openmax_known_score)) + np.exp(openmax_unknown_score)\n",
    "\n",
    "    prob_closed = np.array([scores / total_denominator])\n",
    "    prob_open = np.array([np.exp(openmax_unknown_score) / total_denominator])\n",
    "\n",
    "    probs = np.append(prob_closed.tolist(), prob_open)\n",
    "\n",
    "    assert len(probs) == 8\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74abfeaa",
   "metadata": {},
   "source": [
    "# OpenMax : 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd11f4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "act, pred = my_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9c2cf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "activations, predictions, true_labels = data_setting(act, pred, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f481a195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "위험도 등급 0\n",
      "올바르게 분류된 데이터 개수 333997\n",
      "위험도 등급 1\n",
      "올바르게 분류된 데이터 개수 132126\n",
      "위험도 등급 2\n",
      "올바르게 분류된 데이터 개수 11\n",
      "위험도 등급 3\n",
      "올바르게 분류된 데이터 개수 4128\n",
      "위험도 등급 4\n",
      "올바르게 분류된 데이터 개수 10\n",
      "위험도 등급 5\n",
      "올바르게 분류된 데이터 개수 2160\n",
      "위험도 등급 6\n",
      "올바르게 분류된 데이터 개수 5\n"
     ]
    }
   ],
   "source": [
    "mean_activations, eucos_dist = compute_mav_distances(activations, predictions, true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "909d8ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "weibull_model = weibull_tailfitting(eucos_dist, mean_activations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087d56b6",
   "metadata": {},
   "source": [
    "# OpenMax : 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0e40299b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = tokenizer.texts_to_sequences(test_text)\n",
    "test_X = pad_sequences(test_X, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ef796b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_X = tokenizer.texts_to_sequences(valid_text)\n",
    "valid_X = pad_sequences(valid_X, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c3ede6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_test, pred_test = my_predict(test_X)\n",
    "act_valid, pred_valid = my_predict(valid_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0fc9352d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "open_probs = []\n",
    "\n",
    "\n",
    "for i in range(len(act_test)):\n",
    "    activation = act_test[i] # 입력 데이터를 하나씩 처리합니다\n",
    "\n",
    "    alpharank = 1\n",
    "    num_labels = 7\n",
    "\n",
    "    # 클래스별 가중치 부여 \n",
    "    ranked_list = np.argsort(activation)\n",
    "    ranked_list = ranked_list[::-1]\n",
    "    alpha_weights = [((alpharank + 1) - i) / float(alpharank) for i in range(1, alpharank + 1)]\n",
    "    ranked_alpha = np.zeros(num_labels)\n",
    "\n",
    "    for i in range(0, len(alpha_weights)):\n",
    "        ranked_alpha[ranked_list[i]] = alpha_weights[i]\n",
    "\n",
    "    # OpenMax 확률 계산\n",
    "    openmax_penultimate, openmax_penultimate_unknown = [], []\n",
    "\n",
    "    for categoryid in range(num_labels):\n",
    "        label_weibull = weibull_model[categoryid]['weibull_model']  # 클래스별 weibull 모델을 불러옵니다\n",
    "        label_mav = weibull_model[categoryid]['mean_vec']    # 클래스별 MAV를 불러옵니다\n",
    "        text_dist = spd.euclidean(label_mav, activation[categoryid])/200. + spd.cosine(label_mav, activation[categoryid])\n",
    "\n",
    "        weibull_score = label_weibull.w_score(text_dist)\n",
    "\n",
    "        # activation layer 업데이트\n",
    "        modified_layer_act = activation[categoryid] * (1 - weibull_score * ranked_alpha[categoryid])\n",
    "        openmax_penultimate += [modified_layer_act]  \n",
    "        openmax_penultimate_unknown += [activation[categoryid] - modified_layer_act] \n",
    "        \n",
    "    # 업데이트 된 activation layer로 softmax\n",
    "    openmax_closedset_logit = np.asarray(openmax_penultimate)\n",
    "    openmax_openset_logit = np.sum(openmax_penultimate_unknown)\n",
    "\n",
    "    openmax_probab = compute_open_max_probability(openmax_closedset_logit, openmax_openset_logit)\n",
    "    openmax_probab\n",
    "\n",
    "    open_probs.append(list(openmax_probab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "93bf3b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = [np.argmax(i) for i in open_probs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "71a5b426",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = np.reshape(final, (test.shape[0],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "436502a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5618de86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "level\n",
       "0        1003349\n",
       "7         395766\n",
       "3          12974\n",
       "5           6510\n",
       "1            283\n",
       "2             34\n",
       "dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['openmax'] = final_results\n",
    "submission.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6151ea",
   "metadata": {},
   "source": [
    "# compare: threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "817ecea4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9990696e-01, 2.3572773e-05, 1.3501169e-05, ..., 1.5104749e-05,\n",
       "        1.8109453e-05, 1.6713690e-05],\n",
       "       [9.9999440e-01, 1.7117198e-06, 7.1506111e-07, ..., 9.8989847e-07,\n",
       "        1.3949143e-06, 4.5457637e-07],\n",
       "       [3.6310050e-06, 9.9998266e-01, 2.0094726e-06, ..., 2.8261841e-06,\n",
       "        3.6840543e-06, 2.8195018e-06],\n",
       "       ...,\n",
       "       [6.7222541e-06, 9.9997789e-01, 1.9162346e-06, ..., 2.8178063e-06,\n",
       "        5.5395553e-06, 3.1374154e-06],\n",
       "       [9.9999535e-01, 1.1570390e-06, 6.8094238e-07, ..., 9.4036602e-07,\n",
       "        1.1755834e-06, 3.7139927e-07],\n",
       "       [9.9999440e-01, 1.7117181e-06, 7.1506025e-07, ..., 9.8989767e-07,\n",
       "        1.3949129e-06, 4.5457594e-07]], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for p in range(len(act_test)):\n",
    "    act_test[p] = softmax(act_test[p])\n",
    "act_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d56d2262",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = [np.argmax(i) for i in act_test]\n",
    "test_results = np.reshape(test_result, (test.shape[0], ))\n",
    "test_results[np.where(np.max(act_test, axis=1) < 0.90)] = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d55eba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['threshold'] = test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "561ce69c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1001103\n",
       "1     395656\n",
       "3      12869\n",
       "5       6303\n",
       "7       2985\n",
       "Name: threshold_level, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.threshold_level.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1dd6ea5f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>threshold_level</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000000</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000001</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000002</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000003</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000004</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2418911</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2418912</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2418913</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2418914</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2418915</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1418916 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         level  threshold_level\n",
       "id                             \n",
       "1000000      0                0\n",
       "1000001      0                0\n",
       "1000002      7                1\n",
       "1000003      0                0\n",
       "1000004      7                1\n",
       "...        ...              ...\n",
       "2418911      0                0\n",
       "2418912      0                0\n",
       "2418913      7                1\n",
       "2418914      0                0\n",
       "2418915      0                0\n",
       "\n",
       "[1418916 rows x 2 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
